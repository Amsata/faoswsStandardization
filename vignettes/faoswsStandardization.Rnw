%\VignetteIndexEntry{faoswsStandardization: A package for the standardization of commodity trees in the Statistical Working System}
%\VignetteEngine{knitr::knitr}
\documentclass[nojss]{jss}
\usepackage{url}
\usepackage[sc]{mathpazo}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{breakurl}
\usepackage{hyperref}
\usepackage[ruled, vlined]{algorithm2e}
\usepackage{mathtools}
\usepackage{draftwatermark}
\usepackage{float}
\usepackage{placeins}
\usepackage{mathrsfs}
\usepackage{multirow}
%% \usepackage{mathbbm}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator*{\argmax}{\arg\!\max}

\title{\bf faoswsStandardization: A package for the standardization of commodity trees in the Statistical Working System}

\author{Joshua M. Browning\\ Food and Agriculture
    Organization \\ of the United Nations\\}

\Plainauthor{Joshua M. Browning}

\Plaintitle{faoswsStandardization: Package for Commodity Tree Standardization}

\Shorttitle{Standardization Module}

\Keywords{Standardization, Commodity Trees}
\Plainkeywords{Standardization, Commodity Trees}

\Address{
  Joshua M. Browning\\
  Economics and Social Statistics Division (ESS)\\
  Economic and Social Development Department (ES)\\
  Food and Agriculture Organization of the United Nations (FAO)\\
  Viale delle Terme di Caracalla 00153 Rome, Italy\\
  E-mail: \email{joshua.browning@fao.org}\\
  URL: \url{https://github.com/SWS-Methodology/sws_standardization}
}


\begin{document}
\SweaveOpts{concordance=TRUE}

<<echo=FALSE>>=
if (!exists("faoswsStandardization", .GlobalEnv)) library(faoswsStandardization)
# In devel won't call library, but R CMD build/check will.
@

\section{Introduction}

The term ``standardization'' is used within the FAO to refer to the process of taking a commodity tree and aggregating (or disaggregating) commodities to the parents/children.  For example, we have a wheat commodity tree: wheat is processed into flour, bran, and germ.  Wheat flour is in turn processed into bread, pastries, etc. and so we have a complex tree structure.  We don't wish to create food balance sheets for all of these commodities as we have very little data availability, yet we need to account for these commodities when they are available.  Thus, we standardize data on child commodities up to parent commodities.

In most cases, we only have trade data available for the children commodities.  Production is generally available only at the top level (for example, wheat) and the other elements of the balance (i.e. seed, feed, etc.) are extremely sparse and also generally available at the top level only.

Thus, to create a food balance sheet, we need to standardize detailed trade data (i.e. how many pretzels Mexico imported from Germany, how much mozzarella the US imported from Italy, etc.) into higher levels.  We choose to generally standardize to the first processing level (for example wheat flour) as the extraction rates from the raw commodities to the first processed level should be fairly reliable and because we usually have differing utilizations at this point (wheat flour goes to food while most wheat bran goes to feed).  So, we will take production, feed, seed, food, etc. and ``roll it down'' to the first processed level while we'll ``roll up'' trade data to the first processed level.  Then, we can balance our food balance equation.

One further complication is that trade data is reported in HS (harmonized system) commodity codes while all other elements are reported in CPC (central product classification).  Thus, we must first convert the trade data into CPC codes, standardize it, and then it will be comparable to the other elements of the food balance.

<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
library(ggplot2)
library(faosws)
library(faoswsUtil)
library(faoswsModules)
library(data.table)
opts_chunk$set(fig.path='figure/', fig.align='center', fig.show='hold',
               warning=FALSE, message=FALSE, error=FALSE, tidy=FALSE, 
               results='markup', eval=TRUE, echo=TRUE, cache=FALSE, dpi=200)
options(replace.assign=TRUE,width=80)
assign("depthtrigger", 10, data.table:::.global)
PARAMS <- ReadSettings("C:/Users/Rosa/Favorites/Github/sws_project/faoswsStandardization/modules/standardization/sws.yml", "vignette")
SetClientFiles(PARAMS[["certdir"]])
GetTestEnvironment(
    baseUrl = PARAMS[["server"]],
    token = PARAMS[["token"]]
)
R_SWS_SHARE_PATH <- PARAMS[["share"]]
@ 

\section{Getting Commodity Trees}

\subsection{Pulling data from the system}

Historic commodity trees in FCL (FAO commodity list) codes are available in the system, but they are problematic in that extraction rates were adjustable by the analyst.  Thus, some extraction rates are much too extreme, and so we must work to move all historic extraction rates to meaningful values in our new trees.  Additionally, we must convert the FCL trees into CPC trees, as these codes are what we need for the other elemnts of the FBS.

The first function to use, then, is a function pulling historic commodity trees.  The \texttt{getCommodityTree} function fro \texttt{faoswsUtil} does this rather easily, requiring the user to simply put in countries/years of interest:

<<>>=
tree = getCommodityTree(timePointYears = c("2010", "2011", "2012"))
tree
@

This function works by pulling the relevant data from the shares and ratios data.table (from the old system) and merging them together.

\subsection{Correcting Extraction Rates}

Historic extraction rates were often adjusted and tuned inappropriately, and the new approach should try to use the meaningful information available while fixing and correcting the errors.  A function to remove the extreme values exists in this standardization package, and it's called \texttt{adjustCommodityTree}:

<<>>=
adjustedTree = faoswsStandardization:::adjustCommodityTree(
    commodityTree = copy(tree), nSigma = 1.5,
    parentColname = "measuredItemParentCPC",
    childColname = "measuredItemChildCPC")
@

Let's look at the extraction rates for tapioca of potatoes (CPC code 23230.01) and oil of olive residues (CPC code 21673):

<<echo = FALSE>>=
tapioca = "23230.01"
toPlotOld = tree[measuredItemChildCPC == tapioca, ]
toPlotOld[, treeType := "Original"]
toPlotNew = adjustedTree[measuredItemChildCPC == tapioca, ]
toPlotNew[, treeType := "New"]
toPlot = rbind(toPlotOld, toPlotNew)
ggplot(toPlot, aes(x = extractionRate)) +
    geom_bar() + facet_grid(treeType ~ .) +
    labs(title = "Tapioca of Potatoes")
@

<<echo = FALSE>>=
oliveResidue = "21673"
toPlotOld = tree[measuredItemChildCPC == oliveResidue, ]
toPlotOld[, treeType := "Original"]
toPlotNew = adjustedTree[measuredItemChildCPC == oliveResidue, ]
toPlotNew[, treeType := "New"]
toPlot = rbind(toPlotOld, toPlotNew)
ggplot(toPlot, aes(x = extractionRate)) +
    geom_bar() + facet_grid(treeType ~ .) +
    labs(title = "Oil of Olive Residues")
@

There are still a ton of extraction rates missing, and this is almost surely the wrong thing to do:

<<>>=
tree[is.na(extractionRate), extractionRate := 1]
@

\section{Collecting the data}

Next, we'll grab a subset of the data.  Note that this data is being pulled from the SUA table in the suafbs domain.  This table must be filled by running the Import SUA module (which goes to the agriculture production, trade and tourist domains and pulls data into the SUA domain).  The below query shows how to extract all the SUA data:

<<eval=FALSE>>=
areaKeys = GetCodeList(domain = "suafbs", dataset = "sua", "geographicAreaM49")
areaKeys = areaKeys[type == "country", code]
elemKeys = GetCodeTree(domain = "suafbs", dataset = "sua", "measuredElementSuaFbs")
elemKeys = elemKeys[parent %in% c("51", "61", "71", "91", "101", "111", "121", "131"),
                    paste0(children, collapse = ", ")]
elemKeys = strsplit(elemKeys, ", ")[[1]]
itemKeys = GetCodeList(domain = "suafbs", dataset = "sua", "measuredItemSuaFbs")
itemKeys = itemKeys[, code]
key = DatasetKey(domain = "suafbs", dataset = "sua", dimensions = list(
    geographicAreaM49 = Dimension(name = "geographicAreaM49", keys = areaKeys),
    measuredElementSuaFbs = Dimension(name = "measuredElementSuaFbs", keys = elemKeys),
    measuredItemSuaFbs = Dimension(name = "measuredItemSuaFbs", keys = itemKeys),
    timePointYears = Dimension(name = "timePointYears", keys = "2012")
))
data = GetData(key)
@

However, this data is not very useful for this vignette, as it is very large and also because it will change.  Thus, we will instead use data pulled from the working system at one point in time and saved in this package.  Here's what the data looks like:

<<echo=FALSE, eval=FALSE>>=
# Not shown in vignette, but this is how the saved dataset was generated.
elemKeys = GetCodeTree(domain = "suafbs", dataset = "sua", "measuredElementSuaFbs")
elemKeys = elemKeys[parent %in% c("51", "61", "71", "91", "101", "111", "121", "131"),
                    paste0(children, collapse = ", ")]
elemKeys = strsplit(elemKeys, ", ")[[1]]

# Get all commodities that are in the wheat tree
itemKeys = "0111"
allDescendants = getDescendants(
    tree = unique(tree[, list(measuredItemParentCPC, measuredItemChildCPC)]),
    parentColname = "measuredItemParentCPC",
    childColname = "measuredItemChildCPC")
wheatCodes = allDescendants[measuredItemParentCPC == "0111", 
                            measuredItemChildCPC]
wheatCodes = c("0111", wheatCodes)

key = DatasetKey(domain = "suafbs", dataset = "sua", dimensions = list(
    geographicAreaM49 = Dimension(name = "geographicAreaM49", keys = "840"),
    measuredElementSuaFbs = Dimension(name = "measuredElementSuaFbs", keys = elemKeys),
    measuredItemSuaFbs = Dimension(name = "measuredItemSuaFbs", keys = wheatCodes),
    timePointYears = Dimension(name = "timePointYears", keys = "2011")
))
usaWheat = GetData(key)
save(usaWheat, file = "../data/usaWheat.RData")
@

<<>>=
tree = tree[geographicAreaM49 == "840" & timePointYearsSP == "2012", ]
usaWheat
@

We can now begin with the standardization for this dataset.  The first step is to convert the element/variable codes to standardized names.  We do this because there are many different element/variable codes for one particular element/variable (for example, we can have production in tons, kgs, heads, etc.).  To simplify the code, we perform this conversion to a standardized value so that we don't have to iterate through all the various possible codes.

<<>>=
## DELETE R_SWS_SHARE_PATH WHEN WE HAVE DATA.TABLE IN elementCodesToNames
usaWheat = elementCodesToNames(data = usaWheat,
    elementCol = "measuredElementSuaFbs", itemCol = "measuredItemSuaFbs")
usaWheat
@

The final dataset that we need is the nutrient data.  This data was historically contained in the Ratios table with country/year specific ratios, country specific ratios, and generic ratios.  To easily extract this data, simply call the \texttt{faoswsUtil::getNutritiveFactors} function.

<<>>=
nutrientData = getNutritiveFactors(measuredElement = c("1001", "1003", "1005"),
                                   timePointYears = "2012")
nutrientData = nutrientData[timePointYearsSP == "2012" &
                                geographicAreaM49 == "840", ]
nutrientData[, elementName :=
                 ifelse(measuredElement == "1001", "Calories",
                        ifelse(measuredElement == "1003", "Proteins",
                               "Fats"))]
nutrientData = dcast(nutrientData, measuredItemCPC ~ elementName,
                     value.var = "Value", fun.aggregate = sum)
@

\section{Running the standardization}

The main function performing the standardization is \texttt{standardizationWrapper}.  To call this function, we need "standardization parameters", conveniently generated by defaultStandardizationParameters, but occassionally needing to be overwritten.  Also, the commodity tree needs an additional "target" column to specify if edges should be forward or backwards standardized (see the documentation in "flexible\_aggregation\_of\_FAO\_supply\_utilization\_account.pdf" in the documentation folder of this repository).

<<>>=
params = defaultStandardizationParameters()
params$itemVar = "measuredItemSuaFbs"
params$elementVar = "measuredElementSuaFbs"
params$childVar = "measuredItemChildCPC"
params$parentVar = "measuredItemParentCPC"
params$mergeKey[3] = "measuredItemSuaFbs"
tree[, target := "B"]
params$targetVar = "target"
setnames(tree, "timePointYearsSP", "timePointYears")
setnames(nutrientData, "measuredItemCPC", "measuredItemSuaFbs")
out = standardizationWrapper(data = usaWheat, tree = tree,
                             standParams = params, nutrientData = nutrientData)
out[measuredItemSuaFbs == "0111", ]
@

Thus, this wrapper function performs the entire analysis.  However, to understand the process, let's consider each step individually.

\subsection{Add missing element codes}

When we read in SUA data, it's very possible that we don't have any data points for a particular commodity.  For example, we may not have estimated food for bread, or a country may have had no imports of wheat and therefore we have no record for this commodity.  The function addMissingElements simply introduces these elements that don't exist in the data (for each commodity) by putting them in the data as 0M.  Note how, after running the function, we have 12 records for each commodity.

<<>>=
usaWheat[, .N, measuredItemSuaFbs]
data = faoswsStandardization:::addMissingElements(usaWheat, params)
data[, .N, measuredItemSuaFbs]
@

The package also has a helper function, printSUATable, which accepts the data.table containing our data and prints a nice formatted table with the current SUA.  There is also a markUpdated function which indicates the records which have been changed between two tables, and these two functions can be very useful for understanding what's happening in the standardization process.  Now, our current SUA table has the following records filled in (and we'll make a copy of our current dataset to compare with later):

<<>>=
printCodes = unique(usaWheat$measuredItemSuaFbs)
print(faoswsStandardization:::printSUATable(data = data, standParams = params,
                                            printCodes = printCodes))
old = copy(data)
@

\subsection{Process forward}

Historically, a few commodities were "standardized forward."  The purpose of this step was not clear to the author of this vignette, but the same standardization is still performed in the new approach.  The common example (and possibly the only case) was with the sugar cane and sugar beet trees.  For these commodities, the quantity allocated to processing was calculated as supply minus utilizations (possibly seed or waste).  This quantity allocated to processing was then converted immediately into the child (raw sugar), and the commodity tree is updated by removing those edges.  Thus, balancing will now occur at the raw sugar level.

<<>>=
data = faoswsStandardization:::processForward(data = data, tree = tree, 
                                              standParams = params)$data
## Delete nodes processed forward
forwardParents = tree[get(params$targetVar) == "F",
                      unique(get(params$parentVar))]
tree = tree[!get(params$parentVar) %in% forwardParents, ]
forwardParents
@

Now, we can check which records got updated (which should be none, given that the tree has no forward nodes).

<<>>=
toPrint = faoswsStandardization:::markUpdated(new = data, old = old,
                                              standParams = params)
faoswsStandardization:::printSUATable(data = toPrint, standParams = params,
                                      printCodes = printCodes)
old = copy(data)
@

\subsection{Balance processed products}

We wish to balance the SUA lines, and we do this in a fairly straightforward way.  First, if utilization exceeds supply, then we create enough production to balance.  This production will eventually be derived from the parents of this processed commodity.  If supply exceeds utilization, we increase one utilization element.  Commodities whose main use is food will balance by increasing the food element, and the same process is followed for all other commodities.

<<>>=
level = findProcessingLevel(tree, from = params$parentVar,
                            to = params$childVar, aupusParam = params)
primaryEl = level[processingLevel == 0, get(params$itemVar)]
## Add in elements not in the tree, as they are essentially parents
nonTreeEl = data[[params$itemVar]]
nonTreeEl = nonTreeEl[!nonTreeEl %in% level[[params$itemVar]]]
primaryEl = c(primaryEl, nonTreeEl)
officialProd = data[get(params$elementVar) == params$productionCode & Value > 0,
                    get(params$itemVar)]
## Elements with official production shouldn't have their production 
## updated.  Instead, the food value should be updated, and this is what 
## will happen if that element is not specified to any of the groupings in
## balanceResidual()
faoswsStandardization:::balanceResidual(data, params,
                                        primaryCommodities = primaryEl)
@

Now, we can again examine our updated SUA table:

<<>>=
toPrint = faoswsStandardization:::markUpdated(new = data, old = old,
                                              standParams = params)
faoswsStandardization:::printSUATable(data = toPrint, standParams = params,
                                      printCodes = printCodes)
old = copy(data)
@



\subsubsection{Compute Calories}

If we have nutrient conversion factors for calories, proteins, and/or fats, then we need to perform those calculations at the SUA level.  Moreover, these calculations can be done as soon as we have food quantities available.

<<>>=
nutrientElements = c("Calories", "Fats", "Proteins")
data = merge(data, nutrientData, by = params$itemVar, all.x = TRUE)
## Convert nutrient values into total nutrient info using food
## allocation.
sapply(nutrientElements, function(nutrient){
    data[, c(nutrient) := get(nutrient) * Value[get(params$elementVar) == params$foodCode],
         by = c(params$itemVar)]
})
@

The printSUATable function assumes a different structure than we currently have here (i.e. calories/proteins/fats shouldn't be additional columns).  The current structure is necessary, however, for standardization.  Thus, we'll wait until after the main standardization process before printing the table again.

\subsection{Availability of Parents}

There are many processed products that can each be produced from multiple different parents.  For example, commodities like breakfast cereals, fruit juice nes, beer, etc. all have multiple parents.  For these commodities, we must determine how much of each of the parent commodities was allocated to process this derived product, and we perform this allocation using the availability of each of the parent commodities.  First, we compute the availability for all commodities.

<<>>=
data[, availability := sum(ifelse(is.na(Value), 0, Value) *
                        ifelse(get(params$elementVar) == params$productionCode, 1,
                        ifelse(get(params$elementVar) == params$importCode, 1,
                        ifelse(get(params$elementVar) == params$exportCode, -1,
                        ifelse(get(params$elementVar) == params$stockCode, -1,
                        ifelse(get(params$elementVar) == params$foodCode, -1,
                        ifelse(get(params$elementVar) == params$foodProcCode, 0,
                        ifelse(get(params$elementVar) == params$feedCode, -1,
                        ifelse(get(params$elementVar) == params$wasteCode, -1,
                        ifelse(get(params$elementVar) == params$seedCode, -1,
                        ifelse(get(params$elementVar) == params$industrialCode, -1,
                        ifelse(get(params$elementVar) == params$touristCode, -1,
                        ifelse(get(params$elementVar) == params$residualCode, -1, 0))))))))))))),
     by = c(params$mergeKey)]
@

Now, we need to merge this availability onto our tree data.table so that we know how to correctly standardize the children commodities.

<<>>=
mergeToTree = data[, list(availability = mean(availability)),
                    by = c(params$itemVar)]
setnames(mergeToTree, params$itemVar, params$parentVar)
tree = merge(tree, mergeToTree, by = params$parentVar, all.x = TRUE)
tree[measuredItemParentCPC == "0111",
     c("measuredItemParentCPC", "measuredItemChildCPC", "availability"),
     with = FALSE]
@

We have calculated availability, but so far this only applies to single edges.  In other words, availability for flour is computed using wheat, but availability for bread may be zero.  This is incorrect: bread availability should also derive from wheat.  Thus, we run the \texttt{calculateAvailability} function to "aggregate" the availability for these grandchildren.  Additionally, there is no reason to standardize bread to flour and then to wheat; we can simply standardize all commodities once up to their wheat equivalent.  This is done by "collapsing the edges" with the \texttt{collapseEdges} function.

<<>>=
availability = faoswsStandardization:::calculateAvailability(tree, params)
availability[measuredItemParentCPC == "0111", ]
tree[, availability := NULL]
tree = faoswsStandardization:::collapseEdges(
    edges = tree, parentName = params$parentVar, childName = params$childVar,
    extractionName = params$extractVar, keyCols = NULL)
tree = merge(tree, availability,
             by = c(params$childVar, params$parentVar))
tree[measuredItemParentCPC == "0111",
     c("measuredItemParentCPC", "measuredItemChildCPC", "availability"),
     with = FALSE]
@

Now, we can finally calculate the shares by looking at total availability and the proportion coming from each parent.

<<>>=
tree = tree[, list(share = sum(share),
                   availability = max(availability)),
            by = c("measuredItemChildCPC", "measuredItemParentCPC",
                   "geographicAreaM49", "timePointYears",
                   "extractionRate", "target", "standParentID")]
tree[, newShare := availability / sum(availability, na.rm = TRUE),
          by = c(params$childVar)]
tree[, c(params$shareVar) :=
              ifelse(is.na(newShare), get(params$shareVar), newShare)]
tree[, newShare := NULL]
knitr::kable(tree[measuredItemParentCPC == "0111",
                  c("measuredItemChildCPC", "measuredItemParentCPC",
                    "extractionRate", "availability", "share"),
                  with = FALSE])
@

\subsection{Standardize commodities}

We are finally ready to standardize commodities up to the balancing level.  This process standardizes the quantities back to primary level by dividing by extraction rates and standardizes the calories/proteins/fats back to primary level by adding them.  The general idea is that every element/variable (i.e. imports, exports, ...) is standardized from the processed commodity level back to the primary level.

However, there are also a few special scenarios that occur here that are not, maybe, intuitive:
\begin{itemize}
    \item Production is not standardized.  If a country produces 100 tons of wheat and converts that into 72 tons of flour (via an extraction rate of 0.72), then the standardized production would be 200 tons.  Instead, "production" of a processed commodity is really a conversion from one commodity to another, and shouldn't therefore be aggregated.
    \item Some commodities are standardized up a different tree than from which they were created (i.e. beer can be created out of barley but is standardized into a different tree).  For such "pruned" commodities, only the production value is standardized back to the parent commodity, and it goes into the variable "food for processing."
\end{itemize}

One additional note: currently, we don't have the proper structure specifying how commodities should be standardized.  Generally this is straightforward, as commodities are standardized to the products which created them, but some special cases exist (such as alcohols, generic juices, etc.).  There is an issue to resolve this on the github repository, but the code can function with this data.  We just need to specify what this parent is.

<<>>=
tree[, standParentID := as.character(standParentID)]
tree[measuredItemChildCPC == "24320", standParentID := "Alcohol"]
data = faoswsStandardization:::finalStandardizationToPrimary(
    data = data, tree = tree, standParams = params, sugarHack = FALSE,
    specificTree = FALSE, additiveElements = nutrientElements)
toPrint = faoswsStandardization:::markUpdated(new = data, old = old,
                                              standParams = params)
faoswsStandardization:::printSUATable(data = toPrint, standParams = params,
                                      printCodes = printCodes,
                                      nutrientElements = nutrientElements)
old = copy(data)
@

\subsection{Balancing Primary Commodities}

We can now balance at the primary level.  Balancing is done via maximum likelihood estimation, and is documented in the balancing package.  Standard deviations are also required, and are currently assumed to be 10\% of the value of the variable.

<<>>=
data = data[get(params$elementVar) %in% c(params$productionCode,
        params$importCode, params$exportCode, params$stockCode,
        params$foodCode, params$feedCode, params$seedCode,
        params$touristCode, params$industrialCode, params$wasteCode,
        nutrientElements, params$foodProcCode, params$residualCode), ]
data[, nutrientElement := get(params$elementVar) %in% nutrientElements]
data[, standardDeviation := Value * .1]
data[!get(params$elementVar) %in% nutrientElements,
     balancedValue := faoswsBalancing::balancing(
         param1 = sapply(Value, na2zero),
         param2 = sapply(standardDeviation, na2zero),
         sign = ifelse(get(params$elementVar) %in% c(params$productionCode, params$importCode), 1, -1),
         lbounds = ifelse(get(params$elementVar) %in% c(params$stockCode, params$touristCode), -Inf, 0),
         optimize = "constrOptim", constrTol = 1e-6),
     by = c(params$itemVar)]
## To adjust calories later, compute the ratio for how much food has been 
## adjusted by.  This looks like a "mean", but really we're just using the
## mean to select the one non-NA element.
data[, foodAdjRatio := mean(ifelse(get(params$elementVar) == params$foodCode,
                                   balancedValue / Value, NA),
                            na.rm = TRUE),
     by = c(params$itemVar)]
## The balancedValue will be given for all non-nutrient elements.  Update
## all these elements with their balanced values.
data[!(nutrientElement), Value := balancedValue]
toPrint = faoswsStandardization:::markUpdated(new = data, old = old,
                                              standParams = params)
faoswsStandardization:::printSUATable(data = toPrint, standParams = params,
                                      printCodes = printCodes)
old = copy(data)
@

\subsection{Update calories}

The food quantity may be updated in the balancing process, but the calories will not immediately update to reflect this change.  The simplest approach is to simply adjust the calories by the same ratio that the food quantity is adjusted by.  If no official information is available at the processed level, this approach should be correct.  However, in the case that official flour production (and hence food) is given, a change in the food quantity at the "Wheat and Products" level should not update the flour consumption figures.  This is a future enhancement of the standardization algorithm.

<<>>=
data[(nutrientElement), Value := Value * foodAdjRatio]
toPrint = faoswsStandardization:::markUpdated(new = data, old = old,
                                              standParams = params)
faoswsStandardization:::printSUATable(data = toPrint, standParams = params,
                                      printCodes = printCodes)
old = copy(data)
data[, c("balancedValue", "nutrientElement", "foodAdjRatio") := NULL]
@

\subsection{Aggregate to FBS Level}

The final step in the standardization process is to aggregate up to FBS level.  This standardization is simple: quantities, calories, fats, and proteins are simply added.

<<eval=FALSE, echo=FALSE>>=
# The fbsTree object was created using the getFBSTree function, which isn't
# useful for any user with a different directory structure than Josh :)
fbsTree = getFBSTree()
setnames(fbsTree, "measuredItemCPC", "measuredItemSuaFbs")
fbsTree[,(grep("^fbsID", names(fbsTree))):=lapply(.SD, as.character), .SDcols = grep("^fbsID", names(fbsTree), value=TRUE)]
save(fbsTree, file = "../data/fbsTree.RData")
@

<<>>=
fbsTree
out = faoswsStandardization:::computeFbsAggregate(
    data = data, fbsTree = fbsTree, standParams = params)

out[[1]][Value != 0, ]
out[[2]][Value != 0, ]
out[[3]][Value != 0, ]
out[[4]][Value != 0, ]
@

\end{document}
